{
  "pipelineSpec": {
    "components": {
      "comp-train-tensorflow-model": {
        "executorLabel": "exec-train-tensorflow-model",
        "inputDefinitions": {
          "parameters": {
            "artifact_store": {
              "type": "STRING"
            },
            "base_output_directory": {
              "type": "STRING"
            },
            "bucket_name": {
              "type": "STRING"
            },
            "data_root": {
              "type": "STRING"
            },
            "inference_output_filename": {
              "type": "STRING"
            },
            "location": {
              "type": "STRING"
            },
            "movies_output_filename": {
              "type": "STRING"
            },
            "network": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "service_account": {
              "type": "STRING"
            },
            "tensorboard": {
              "type": "STRING"
            },
            "timestamp": {
              "type": "STRING"
            },
            "train_output_filename": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "gcp_resources": {
              "type": "STRING"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-train-tensorflow-model": {
          "container": {
            "args": [
              "--type",
              "CustomJob",
              "--payload",
              "{\"display_name\": \"Train tensorflow model\", \"job_spec\": {\"worker_pool_specs\": [{\"machine_spec\": {\"machine_type\": \"n1-standard-32\", \"accelerator_type\": \"NVIDIA_TESLA_T4\", \"accelerator_count\": 2}, \"replica_count\": 1, \"container_spec\": {\"image_uri\": \"gcr.io/qwiklabs-gcp-04-424f1fdacc59/moviecust:0.1\", \"command\": [\"sh\", \"-c\", \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'tensorflow==2.6.2' 'tensorflow-recommenders==0.6.0' 'pandas==1.3.2' 'google-cloud-bigquery==2.34.2' 'pyarrow==7.0.0' 'google-cloud-storage==1.42.2' 'kfp==1.8.10' && \\\"$0\\\" \\\"$@\\\"\\n\", \"sh\", \"-ec\", \"program_path=$(mktemp -d)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path/ephemeral_component.py\\\"\\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\", \"\\nimport kfp\\nfrom kfp.v2 import dsl\\nfrom kfp.v2.dsl import *\\nfrom typing import *\\n\\ndef train_tensorflow_model(\\n    data_root: str,\\n    movies_output_filename: str,\\n    train_output_filename: str,\\n    inference_output_filename: str,\\n    artifact_store: str,\\n    timestamp: str,\\n    bucket_name: str,\\n):\\n    import os\\n    import json\\n    import datetime\\n    import tensorflow as tf\\n    import tensorflow_recommenders as tfrs\\n    import time\\n    import subprocess\\n    import sys\\n    import tempfile\\n\\n    from mubireco.model.model_definition import create_model\\n    from mubireco.data.train import TrainDataset\\n    from mubireco.data.inference import InferenceDataset\\n\\n    from mubireco.utils.configuration import Configuration\\n\\n    batch_size = 10000\\n    num_evals = 100\\n    lr = 0.1\\n    timestamp_train = datetime.datetime.now().strftime(\\\"%Y%m%d%H%M%S\\\")\\n    embedding_dim = 32\\n    num_test_sample = 4\\n\\n    output_dir = os.path.join(f\\\"gs://{bucket_name}\\\", timestamp, timestamp_train)\\n\\n    config = Configuration(\\\"mubireco/config/config.yaml\\\")\\n\\n    ds_train = TrainDataset(config).read_tf_dataset()\\n    ds_inf = InferenceDataset(config).read_tf_dataset()\\n\\n    num_train_sample = len(ds_train) - num_test_sample\\n\\n    tf.random.set_seed(42)\\n    ds_train = ds_train.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\\n\\n    ds_train_shuffled = ds_train.take(num_train_sample)\\n    ds_val_shuffled = ds_train.skip(num_train_sample)\\n\\n    cached_train = ds_train_shuffled.batch(batch_size).repeat().cache()\\n    cached_val = ds_val_shuffled.batch(batch_size).cache()\\n\\n    steps_per_epoch = len(ds_train) // (batch_size * num_evals)\\n\\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\\n        os.path.join(output_dir, \\\"checkpoints\\\"), save_weights_only=True, verbose=1\\n    )\\n    tensorboard_cb = tf.keras.callbacks.TensorBoard(\\n        os.path.join(output_dir, \\\"tensorboard\\\"), histogram_freq=1\\n    )\\n\\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\\n                                                         monitor=\\\"factorized_top_k/top_100_categorical_accuracy\\\")\\n\\n    # For MirroredStrategy #\\n    strategy = tf.distribute.MirroredStrategy()\\n\\n    with strategy.scope():\\n        # End #\\n        model = create_model(batch_size, embedding_dim, config)\\n        model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=lr))\\n\\n    options = tf.data.Options()\\n    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\\n    cached_train = cached_train.with_options(options)\\n    cached_val = cached_val.with_options(options)\\n\\n    start = time.time()\\n    history = model.fit(\\n        cached_train,\\n        # validation_data=cached_val,\\n        steps_per_epoch=steps_per_epoch,\\n        epochs=num_evals,\\n        verbose=1,  # 0=silent, 1=progress bar, 2=one line per epoch\\n        callbacks=[checkpoint_cb, tensorboard_cb]  # , early_stopping_cb],\\n    )\\n    print(\\\"Training time with single GPUs: {}\\\".format(time.time() - start))\\n\\n    results = model.evaluate(cached_val, return_dict=True)\\n\\n    filename_results = \\\"eval_results.json\\\"\\n    with open(filename_results, \\\"w\\\") as f:\\n        json.dump(results, f)\\n    gcs_model_path = os.path.join(output_dir, filename_results)\\n    subprocess.check_call([\\\"gsutil\\\", \\\"cp\\\", filename_results, gcs_model_path], stderr=sys.stdout)\\n    print(f\\\"Saved model in: {gcs_model_path}\\\")\\n\\n    index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\\n\\n    index.index_from_dataset(\\n        tf.data.Dataset.zip(\\n            (ds_inf.map(lambda x: x[\\\"user_id\\\"]).batch(batch_size),\\n             ds_inf.batch(batch_size).map(model.candidate_model)))\\n    )\\n\\n    # example, to keep otherwise bug in saved model\\n    _, _ = index(tf.constant([42]))\\n\\n    with tempfile.TemporaryDirectory() as tmp:\\n        # Save the index.\\n        tf.saved_model.save(index, os.path.join(output_dir, \\\"models\\\"))\\n\\n\"], \"args\": [\"--executor_input\", \"{{$.json_escape[1]}}\", \"--function_to_execute\", \"train_tensorflow_model\"]}, \"disk_spec\": {\"boot_disk_type\": \"pd-ssd\", \"boot_disk_size_gb\": 100}}], \"service_account\": \"{{$.inputs.parameters['service_account']}}\", \"network\": \"{{$.inputs.parameters['network']}}\", \"tensorboard\": \"{{$.inputs.parameters['tensorboard']}}\", \"base_output_directory\": {\"output_uri_prefix\": \"{{$.inputs.parameters['base_output_directory']}}\"}}}",
              "--project",
              "{{$.inputs.parameters['project']}}",
              "--location",
              "{{$.inputs.parameters['location']}}",
              "--gcp_resources",
              "{{$.outputs.parameters['gcp_resources'].output_file}}"
            ],
            "command": [
              "python3",
              "-u",
              "-m",
              "google_cloud_pipeline_components.container.experimental.gcp_launcher.launcher"
            ],
            "image": "gcr.io/ml-pipeline/google-cloud-pipeline-components:0.2.1"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "tensorflow-train-pipeline"
    },
    "root": {
      "dag": {
        "tasks": {
          "train-tensorflow-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-train-tensorflow-model"
            },
            "inputs": {
              "parameters": {
                "artifact_store": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://{{$.inputs.parameters['pipelineparam--model_name']}}-kfp-artifact-store/"
                    }
                  }
                },
                "base_output_directory": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "bucket_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "{{$.inputs.parameters['pipelineparam--model_name']}}-kfp-artifact-store"
                    }
                  }
                },
                "data_root": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://{{$.inputs.parameters['pipelineparam--model_name']}}-kfp-artifact-store/20220316160407/data"
                    }
                  }
                },
                "inference_output_filename": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "inference_mubi.tfdataset"
                    }
                  }
                },
                "location": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "us-central1"
                    }
                  }
                },
                "movies_output_filename": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "movies_mubi.tfdataset"
                    }
                  }
                },
                "network": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "pipelineparam--model_name": {
                  "componentInputParameter": "model_name"
                },
                "project": {
                  "componentInputParameter": "project_id"
                },
                "service_account": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "tensorboard": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "timestamp": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "20220316160407"
                    }
                  }
                },
                "train_output_filename": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "train_mubi.tfdataset"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "Vertex Training for TF model"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "model_name": {
            "type": "STRING"
          },
          "project_id": {
            "type": "STRING"
          },
          "seq_length": {
            "type": "INT"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.10"
  },
  "runtimeConfig": {}
}